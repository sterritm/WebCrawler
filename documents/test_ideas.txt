Test cases:

Client-side:

Graphs (no keyword)):
1) Single node, no edges
2) 0 nodes
3) Two nodes, 1 edge
4) Two nodes, 2 edges loop
6) 3 nodes, 2 edges, linked list format
6) 3 nodes, 2 edges, tree format
7) 3 nodes, 3 edges, last node points back to first node
8) Two nodes, 0 edges
9) 4 nodes, 3 edges, linked list to tree
10) 1 node, 1 edge pointing to itself
11) 3 nodes, edge to every node possible (heavily populated)

Graphs keyword:
1) 1 node, keyword
2) 2 nodes, 1 edge, keyword on second
3) 2 nodes, 1 edge, keyword on first
4) 3 nodes, 2 edges, keyword in middle
5) 2 nodes, 1 edge, keyword found on both
6) 3 nodes, 2 edges, keyword found on two

Invalid graph formats:
1) invalid data format
2) node missing title
3) node missing URL

Invalid JSON formats:
4) start URL missing
5) No URLs
6) No cookie sent


Random graph constructor

server-side:

JSON to server:
	valid json, no cookie, no keyword
	valid json, no cookie, keyword
	valid json, with only cookie and method
	valid json with cookie + page and keyword (how should this behave?)
	
	invalid page data type
	invalid method
	invalid limit data type
	invalid keyword data type
	invalid cookie data type
	
Web page parser:
	Empty page
	Page with no links
	Page with only 1 link
	Page with 1 link surrounded by garbage
	An error page (what should the server do if it hits a 404 error?)
	Page with only multiple links
	Page with multiple links and lots of garbage
	Page with link hidden in source code???

Web Crawler:
	repeat tests from client's graph section
	
Cookie:
	valid cookie
	cookie not on server
	